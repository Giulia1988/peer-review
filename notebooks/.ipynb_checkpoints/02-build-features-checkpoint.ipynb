{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Notebook\n",
    "\n",
    "Clean and extract features from raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Steps\n",
    "\n",
    "1. Split the data into training and test data set\n",
    "1. Clean the data (transform null values)\n",
    "1. Scale necessary attributes (normalization, standardization)\n",
    "1. Save transformed data for model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Add directory above current directory to path\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# model\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# k-fold cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# serializing, compressing, and loading the models\n",
    "import joblib\n",
    "\n",
    "# performance\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Load comma separated data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "settings._interpolation = configparser.ExtendedInterpolation()\n",
    "settings.read('../config')\n",
    "settings.sections()\n",
    "\n",
    "#path to data folder\n",
    "csv_path = \"../\" + settings.get('Data', 'raw')\n",
    "data = pd.read_csv(csv_path, sep=\",\")\n",
    "version = settings.get('Run', 'version')\n",
    "\n",
    "#Prepare data directory for current run\n",
    "data_path = \"../\" + settings.get('Path', 'data') + \"run_\" + version\n",
    "transform_path = data_path + \"/transform/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    os.makedirs(transform_path)\n",
    "else:\n",
    "    shutil.rmtree(data_path)           # Removes all the subdirectories!\n",
    "    os.makedirs(data_path)\n",
    "    os.makedirs(transform_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Training and Test Dataset\n",
    "> uses scikit-learn\n",
    "\n",
    "Performing this early minimizes generalization and bias you may inadvertently apply to your system.\n",
    "Simply put, a test set of data involves: picking ~20% of the instances randomly and setting them aside.\n",
    "\n",
    "Some considerations for sampling methods that generate the test set:\n",
    "1. you don't want your model to see the entire dataset\n",
    "1. you want to be able to fetch new data for training\n",
    "1. you want to maintain the same percentage of training data against the entire dataset\n",
    "1. you want a representative training dataset (~7% septic positive)\n",
    "\n",
    "https://realpython.com/train-test-split-python-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sets 10%/15%/20% of the data aside for testing, sets the random number generate to it always generates the same shuffled indicies\n",
    "# x = 2 dimensional array with inputs\n",
    "# X_train is the training part of the first sequence (x)\n",
    "# X_test is the test part of the first sequence (x)\n",
    "# y = 1 dimensional array with outputs\n",
    "# y_train is the labeled training part of the second sequence\n",
    "# y_test is the labeled test part of the second sequence\n",
    "# axis Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’)\n",
    "# test_size is the amount of the total dataset to set aside for testing = 10%\n",
    "# random state fixes the randomization so you get the same results each time\n",
    "# Shuffle before the data is split, it is shuffled\n",
    "# stratified splitting keeps the proportion of y values trhough the train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data.drop([\"Age\", \"Unit1\", \"Unit2\", \"HospAdmTime\", \"ICULOS\", \"Gender\", \"Bilirubin_direct\", \"TroponinI\", \"isSepsis\"], axis=1),\n",
    "    data[\"isSepsis\"], test_size=0.20,\n",
    "    random_state=42, stratify=data[\"isSepsis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean the Data\n",
    "Instead of preparing data manually, write functions to:\n",
    "1. reproduce transformations easily on any dataset (e.g., data refresh)\n",
    "1. builds a library of functions to reuse in future projects\n",
    "1. use functions in live stream to transform new data before inferencing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. transform current and future null values\n",
    "1. impute median for missing attributes (>7k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Transform missing values from numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 80.  ,  99.  ,   0.  , ...,  15.  ,   0.  , 341.  ],\n",
       "       [ 84.  ,  95.  ,  37.06, ...,  13.5 ,   0.  , 292.  ],\n",
       "       [ 78.  , 100.  ,   0.  , ...,   7.5 ,   0.  , 135.  ],\n",
       "       ...,\n",
       "       [ 76.  ,  98.  ,   0.  , ...,   6.2 ,   0.  ,  77.  ],\n",
       "       [ 80.  , 100.  ,  36.4 , ...,  25.7 ,   0.  ,   0.  ],\n",
       "       [100.5 ,  99.  ,   0.  , ...,   0.6 ,  77.  , 172.  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create simpleimputer instance\n",
    "# replace attributes missing values with median of the attribute\n",
    "imputer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# fit applies the imputer to ALL numeric data in case new data includes null values\n",
    "# when system goes live\n",
    "# results are stored in a imputer.statistics_ value\n",
    "imputer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>PTT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>25.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>84.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>37.06</td>\n",
       "      <td>134.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>121.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>79.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>114.5</td>\n",
       "      <td>87.50</td>\n",
       "      <td>71.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>31.1</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>102.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.44</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>28.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HR  O2Sat   Temp    SBP     MAP   DBP  Resp  EtCO2  BaseExcess  HCO3  \\\n",
       "23     80.0   99.0   0.00  129.0  100.00  77.0  18.0    0.0         0.0  22.0   \n",
       "1084   84.0   95.0  37.06  134.0   84.00   0.0  17.0    0.0         0.0  22.0   \n",
       "414    78.0  100.0   0.00  129.0   80.00  57.0  10.0    0.0         0.0  24.0   \n",
       "437    79.5   99.0  37.00  114.5   87.50  71.5  31.5    0.0         1.0  25.0   \n",
       "671   102.0   98.0  36.44  122.0   70.67   0.0  16.0    0.0         0.0  24.0   \n",
       "\n",
       "      ...  Magnesium  Phosphate  Potassium  Bilirubin_total   Hct   Hgb  \\\n",
       "23    ...        1.8        2.8        3.8              0.0  28.0   9.3   \n",
       "1084  ...        2.5        5.1        4.1              0.0  31.6  10.7   \n",
       "414   ...        1.8        2.7        4.0              0.0  23.6   8.0   \n",
       "437   ...        1.7        3.3        4.0              0.0  32.9  11.3   \n",
       "671   ...        1.9        2.3        3.8              3.3  28.2   9.3   \n",
       "\n",
       "        PTT   WBC  Fibrinogen  Platelets  \n",
       "23     25.8  15.0         0.0      341.0  \n",
       "1084  121.5  13.5         0.0      292.0  \n",
       "414     0.0   7.5         0.0      135.0  \n",
       "437    31.1  18.4         0.0      268.0  \n",
       "671    38.5  11.0         0.0      160.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the trained imputer to transform the training set replacing the\n",
    "# missing values with learn medians\n",
    "N = imputer.transform(X_train)\n",
    "# result above is plain NumPy array with transformed features\n",
    "# put back to a pandas DataFrame\n",
    "M = pd.DataFrame(N, columns=X_train.columns, index=X_train.index)\n",
    "M.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 Feature Scaling\n",
    "1. ML algorithms don't work well when numeric attributes have very different scales\n",
    "    (e.g. HR max 184,  pH max 7.67)\n",
    "1. Scaling target values is not necessary\n",
    "1. Apply\n",
    "    1. normalization (MinMaxScaler) bounds the values to a specific range (e.g. 0-1)\n",
    "    1. standardization (StandardScaler) less affected by outliers does not bound to range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>PTT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.114565</td>\n",
       "      <td>0.294776</td>\n",
       "      <td>-1.001265</td>\n",
       "      <td>0.514898</td>\n",
       "      <td>1.243452</td>\n",
       "      <td>1.398276</td>\n",
       "      <td>0.122276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.026082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240464</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>-0.116594</td>\n",
       "      <td>-0.116098</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>-0.230317</td>\n",
       "      <td>1.239055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>0.083934</td>\n",
       "      <td>0.106096</td>\n",
       "      <td>1.008413</td>\n",
       "      <td>0.663885</td>\n",
       "      <td>0.440230</td>\n",
       "      <td>-1.118581</td>\n",
       "      <td>-0.037854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.026082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046187</td>\n",
       "      <td>1.325732</td>\n",
       "      <td>0.277770</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.269448</td>\n",
       "      <td>4.135162</td>\n",
       "      <td>0.470037</td>\n",
       "      <td>-0.230317</td>\n",
       "      <td>0.835872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-0.213814</td>\n",
       "      <td>0.341947</td>\n",
       "      <td>-1.001265</td>\n",
       "      <td>0.514898</td>\n",
       "      <td>0.239425</td>\n",
       "      <td>0.744547</td>\n",
       "      <td>-1.158764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>0.225535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240464</td>\n",
       "      <td>0.084862</td>\n",
       "      <td>0.204289</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>-0.565536</td>\n",
       "      <td>-0.474105</td>\n",
       "      <td>-0.947890</td>\n",
       "      <td>-0.435756</td>\n",
       "      <td>-0.230317</td>\n",
       "      <td>-0.455959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>-0.139377</td>\n",
       "      <td>0.294776</td>\n",
       "      <td>1.005159</td>\n",
       "      <td>0.082834</td>\n",
       "      <td>0.615935</td>\n",
       "      <td>1.218500</td>\n",
       "      <td>2.284029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387765</td>\n",
       "      <td>0.351344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125361</td>\n",
       "      <td>0.395079</td>\n",
       "      <td>0.204289</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.383364</td>\n",
       "      <td>0.434682</td>\n",
       "      <td>0.353204</td>\n",
       "      <td>1.209769</td>\n",
       "      <td>-0.230317</td>\n",
       "      <td>0.638395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0.977177</td>\n",
       "      <td>0.247606</td>\n",
       "      <td>0.974792</td>\n",
       "      <td>0.306315</td>\n",
       "      <td>-0.228954</td>\n",
       "      <td>-1.118581</td>\n",
       "      <td>-0.197984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>0.225535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355568</td>\n",
       "      <td>-0.121950</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>1.840268</td>\n",
       "      <td>-0.096187</td>\n",
       "      <td>-0.116098</td>\n",
       "      <td>0.662789</td>\n",
       "      <td>0.092623</td>\n",
       "      <td>-0.230317</td>\n",
       "      <td>-0.250253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HR     O2Sat      Temp       SBP       MAP       DBP      Resp  \\\n",
       "23   -0.114565  0.294776 -1.001265  0.514898  1.243452  1.398276  0.122276   \n",
       "1084  0.083934  0.106096  1.008413  0.663885  0.440230 -1.118581 -0.037854   \n",
       "414  -0.213814  0.341947 -1.001265  0.514898  0.239425  0.744547 -1.158764   \n",
       "437  -0.139377  0.294776  1.005159  0.082834  0.615935  1.218500  2.284029   \n",
       "671   0.977177  0.247606  0.974792  0.306315 -0.228954 -1.118581 -0.197984   \n",
       "\n",
       "      EtCO2  BaseExcess      HCO3  ...  Magnesium  Phosphate  Potassium  \\\n",
       "23      0.0    0.043109 -0.026082  ...   0.240464   0.136565   0.057328   \n",
       "1084    0.0    0.043109 -0.026082  ...   1.046187   1.325732   0.277770   \n",
       "414     0.0    0.043109  0.225535  ...   0.240464   0.084862   0.204289   \n",
       "437     0.0    0.387765  0.351344  ...   0.125361   0.395079   0.204289   \n",
       "671     0.0    0.043109  0.225535  ...   0.355568  -0.121950   0.057328   \n",
       "\n",
       "      Bilirubin_total       Hct       Hgb       PTT       WBC  Fibrinogen  \\\n",
       "23          -0.222119 -0.116594 -0.116098  0.131474  0.696486   -0.230317   \n",
       "1084        -0.222119  0.250722  0.269448  4.135162  0.470037   -0.230317   \n",
       "414         -0.222119 -0.565536 -0.474105 -0.947890 -0.435756   -0.230317   \n",
       "437         -0.222119  0.383364  0.434682  0.353204  1.209769   -0.230317   \n",
       "671          1.840268 -0.096187 -0.116098  0.662789  0.092623   -0.230317   \n",
       "\n",
       "      Platelets  \n",
       "23     1.239055  \n",
       "1084   0.835872  \n",
       "414   -0.455959  \n",
       "437    0.638395  \n",
       "671   -0.250253  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "O = scaler.fit_transform(N)\n",
    "P = pd.DataFrame(O, columns=X_train.columns, index=X_train.index)\n",
    "P.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Transformation Pipeline\n",
    "\n",
    "Common to apply many transformation steps in a specific order (fill the nulls before you apply the scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this pipeline should work for all the estimators/algorithms\n",
    "pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='constant')),\n",
    "                    ('std_scaler', StandardScaler()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this is the transformed data to train from\n",
    "X_train_prepared = pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# neural networks sometimes expect a 0-1 normalized scale and perform better\n",
    "pipeline_minmax = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='constant')),\n",
    "                    ('minMax', MinMaxScaler()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this is the transformed data to train the MLP from\n",
    "X_train_prepared_m = pipeline_minmax.fit_transform(X_train)\n",
    "X_test_prepared=pipeline_minmax.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save the data for model training\n",
    "\n",
    "Common to apply many transformation steps in a specific order (fill the nulls before you apply the scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compress and save the pipeline\n",
    "\n",
    "joblib.dump(pipeline, transform_path + \"pipeline.pkl\")\n",
    "joblib.dump(pipeline_minmax, transform_path + \"pipeline_minmax.pkl\")\n",
    "\n",
    "#Save the transformed data into data/transform folder\n",
    "\n",
    "np.savetxt(transform_path + \"X_train_prepared_m.csv\", X_train_prepared_m, delimiter=\",\")\n",
    "np.savetxt(transform_path + \"X_train_prepared.csv\", X_train_prepared, delimiter=\",\")\n",
    "np.savetxt(transform_path + \"X_train.csv\", X_train, delimiter=\",\")\n",
    "np.savetxt(transform_path + \"X_test.csv\", X_test, delimiter=\",\")\n",
    "np.savetxt(transform_path + \"X_test_prepared.csv\", X_test_prepared, delimiter=\",\")\n",
    "np.savetxt(transform_path + \"y_train.csv\", y_train, delimiter=\",\")\n",
    "np.savetxt(transform_path + \"y_test.csv\", y_test, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
